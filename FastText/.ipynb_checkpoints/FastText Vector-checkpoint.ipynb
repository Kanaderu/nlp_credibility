{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath\n",
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x7f6805bc0910>\n"
     ]
    }
   ],
   "source": [
    "# Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FastText(size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x7f6805bc0430>\n"
     ]
    }
   ],
   "source": [
    "# saving a model trained via Gensim's fastText implementation\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='saved_model_gensim-', delete=False) as tmp:\n",
    "    model.save(tmp.name, separately=[])\n",
    "\n",
    "loaded_model = FastText.load(tmp.name)\n",
    "print(loaded_model)\n",
    "\n",
    "os.unlink(tmp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('night' in model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print('nights' in model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 0.09328159,  0.00293368, -0.5825525 ,  0.4804867 ,  0.60628265,\n",
      "       -0.32440963, -0.1900126 , -0.04720529,  0.4296245 ,  0.33883592,\n",
      "       -0.64138836, -0.01311536, -0.6803271 ,  0.41426086,  0.28293076,\n",
      "       -0.0627832 , -0.19809733,  0.18880153,  0.24111313, -0.38077462,\n",
      "       -0.24081866,  0.27846235, -0.3800002 ,  0.02428199, -0.8321537 ,\n",
      "        0.73555607,  0.12400806,  0.18025942,  0.41238812,  0.01032294,\n",
      "       -0.6513453 ,  0.23436972,  0.08221383, -0.48725444,  0.47087866,\n",
      "        0.10562417, -0.16273548, -0.06727337,  0.4205416 ,  0.21674827,\n",
      "       -0.01219405, -0.0714284 ,  0.39351365, -0.06149524,  0.12587579,\n",
      "        0.18490611, -0.1297693 ,  0.21808794, -0.01785759, -0.3867093 ,\n",
      "       -0.5744982 , -0.55261075,  0.06789429,  0.01309222,  0.40188548,\n",
      "       -0.80584663, -0.10843118, -0.18335408,  0.0093728 , -0.03013261,\n",
      "        0.21745446, -0.11712731, -0.49495208, -0.10418411, -0.5365404 ,\n",
      "        0.34694734,  0.00929465,  0.15118392,  0.02868891,  0.47538498,\n",
      "       -0.57173127, -0.51680005, -0.00667727, -0.12093855, -0.3368226 ,\n",
      "        0.02966731,  0.27629155,  0.11584879, -0.14146517,  0.17983645,\n",
      "        0.45853332,  0.0526085 , -0.16986139,  0.4611266 , -0.3918258 ,\n",
      "       -0.25860277,  0.11962561,  0.28996187,  0.3236596 ,  0.29987994,\n",
      "       -0.17810172,  0.12381194, -0.03415641, -0.19175571, -0.27610746,\n",
      "        0.56893945,  0.28520146,  0.448182  ,  0.5551611 ,  0.47786394],\n",
      "      dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b7497f2362da>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  print(model['night'])\n"
     ]
    }
   ],
   "source": [
    "print(model['night'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 0.08200456,  0.00311313, -0.5067949 ,  0.41726106,  0.52656895,\n",
      "       -0.28365764, -0.1659721 , -0.04026311,  0.3734566 ,  0.29544747,\n",
      "       -0.56008923, -0.01283315, -0.59213215,  0.36180642,  0.24214585,\n",
      "       -0.0543477 , -0.17448288,  0.16253269,  0.2081355 , -0.3317107 ,\n",
      "       -0.20949489,  0.24317653, -0.33130634,  0.0217941 , -0.72467506,\n",
      "        0.63971657,  0.107851  ,  0.15729423,  0.35894045,  0.00855084,\n",
      "       -0.5645802 ,  0.20512997,  0.07021042, -0.4259228 ,  0.40937784,\n",
      "        0.09158499, -0.1401106 , -0.0598051 ,  0.36575964,  0.18934657,\n",
      "       -0.00970295, -0.06229048,  0.34186652, -0.05180154,  0.10844268,\n",
      "        0.16112216, -0.11646864,  0.19153272, -0.01617219, -0.33500212,\n",
      "       -0.5023316 , -0.47996855,  0.06021847,  0.01235424,  0.35026821,\n",
      "       -0.7012407 , -0.09444979, -0.15837988,  0.00583872, -0.02591816,\n",
      "        0.1887479 , -0.10276058, -0.43040594, -0.09123224, -0.46725813,\n",
      "        0.30125707,  0.00819573,  0.1314019 ,  0.02672475,  0.41434544,\n",
      "       -0.49738482, -0.44916365, -0.00586792, -0.10612746, -0.29283258,\n",
      "        0.02501703,  0.24044831,  0.10100226, -0.12116358,  0.1556716 ,\n",
      "        0.39973852,  0.0455979 , -0.14862396,  0.40029854, -0.33984807,\n",
      "       -0.22433907,  0.10611439,  0.2535529 ,  0.28091085,  0.26159385,\n",
      "       -0.1552731 ,  0.10746224, -0.03109937, -0.16654801, -0.24002144,\n",
      "        0.49524483,  0.24718213,  0.388477  ,  0.48258102,  0.4158336 ],\n",
      "      dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-3eba5d80fb32>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  print(model['nights'])\n"
     ]
    }
   ],
   "source": [
    "print(model['nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity operations\n",
    "\n",
    "Similarity operations work the same way as word2vec. **Out-of-vocabulary words can also be used, provided they have at least one character ngram present in the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-440b9996a295>:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  print(model.similarity(\"night\", \"nights\"))\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity(\"night\", \"nights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-fc6a32c4ff75>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  print(model.most_similar(\"nights\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('study', 0.998267650604248),\n",
      " ('Arafat', 0.9982653856277466),\n",
      " ('boat', 0.9982650876045227),\n",
      " ('often', 0.9982650876045227),\n",
      " ('\"That', 0.9982621669769287),\n",
      " ('Arafat,', 0.9982602596282959),\n",
      " ('Endeavour', 0.9982555508613586),\n",
      " ('north.', 0.998253583908081),\n",
      " ('details', 0.9982484579086304),\n",
      " ('stage', 0.9982419013977051)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"nights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-10ff9d1d3a62>:1: DeprecationWarning: Call to deprecated `n_similarity` (Method will be removed in 4.0.0, use self.wv.n_similarity() instead).\n",
      "  print(model.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant']))\n"
     ]
    }
   ],
   "source": [
    "print(model.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactically similar words generally have high similarity in fastText models, since a large number of the component char-ngrams will be the same. As a result, fastText generally does better at syntactic tasks than Word2Vec. A detailed comparison is provided [here](https://radimrehurek.com/gensim/auto_examples/tutorials/Word2Vec_FastText_Comparison.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other similarity operations\n",
    "\n",
    "The example training corpus is a toy corpus, results are not expected to be good, for proof-of-concept only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'breakfast'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-936cf8a1b248>:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
      "/home/fandav/.conda/envs/nlp/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'correct': [], 'incorrect': [], 'section': 'capital-common-countries'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'capital-world'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'currency'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'city-in-state'},\n",
      " {'correct': [],\n",
      "  'incorrect': [('HE', 'SHE', 'HIS', 'HER'), ('HIS', 'HER', 'HE', 'SHE')],\n",
      "  'section': 'family'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'gram1-adjective-to-adverb'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'gram2-opposite'},\n",
      " {'correct': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
      "              ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
      "              ('LONG', 'LONGER', 'GREAT', 'GREATER')],\n",
      "  'incorrect': [('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
      "                ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
      "                ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
      "                ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
      "                ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
      "                ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
      "                ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
      "                ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
      "                ('LOW', 'LOWER', 'LONG', 'LONGER')],\n",
      "  'section': 'gram3-comparative'},\n",
      " {'correct': [('GREAT', 'GREATEST', 'LARGE', 'LARGEST')],\n",
      "  'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
      "                ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
      "                ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
      "                ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
      "                ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
      "                ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
      "                ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
      "                ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
      "                ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
      "                ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
      "                ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')],\n",
      "  'section': 'gram4-superlative'},\n",
      " {'correct': [('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
      "              ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
      "              ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
      "              ('SAY', 'SAYING', 'PLAY', 'PLAYING')],\n",
      "  'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
      "                ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
      "                ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
      "                ('GO', 'GOING', 'SAY', 'SAYING'),\n",
      "                ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
      "                ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
      "                ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
      "                ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
      "                ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
      "                ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
      "                ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
      "                ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
      "                ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
      "                ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
      "                ('SAY', 'SAYING', 'GO', 'GOING'),\n",
      "                ('SAY', 'SAYING', 'RUN', 'RUNNING')],\n",
      "  'section': 'gram5-present-participle'},\n",
      " {'correct': [('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
      "              ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
      "              ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
      "              ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
      "              ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
      "              ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "              ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
      "              ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN')],\n",
      "  'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
      "                ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
      "                ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
      "                ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
      "                ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
      "                ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
      "                ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI')],\n",
      "  'section': 'gram6-nationality-adjective'},\n",
      " {'correct': [('PAYING', 'PAID', 'SAYING', 'SAID')],\n",
      "  'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
      "                ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
      "                ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
      "                ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
      "                ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
      "                ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
      "                ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
      "                ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
      "                ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
      "                ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
      "                ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
      "                ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
      "                ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
      "                ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
      "                ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
      "                ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
      "                ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
      "                ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
      "                ('TAKING', 'TOOK', 'SAYING', 'SAID')],\n",
      "  'section': 'gram7-past-tense'},\n",
      " {'correct': [('MAN', 'MEN', 'CHILD', 'CHILDREN')],\n",
      "  'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
      "                ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
      "                ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
      "                ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
      "                ('CAR', 'CARS', 'MAN', 'MEN'),\n",
      "                ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
      "                ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
      "                ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
      "                ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
      "                ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
      "                ('MAN', 'MEN', 'CAR', 'CARS')],\n",
      "  'section': 'gram8-plural'},\n",
      " {'correct': [], 'incorrect': [], 'section': 'gram9-plural-verbs'},\n",
      " {'correct': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
      "              ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
      "              ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
      "              ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
      "              ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
      "              ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
      "              ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
      "              ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
      "              ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
      "              ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
      "              ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
      "              ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
      "              ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
      "              ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "              ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
      "              ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
      "              ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
      "              ('MAN', 'MEN', 'CHILD', 'CHILDREN')],\n",
      "  'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
      "                ('HIS', 'HER', 'HE', 'SHE'),\n",
      "                ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
      "                ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
      "                ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
      "                ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
      "                ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
      "                ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
      "                ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
      "                ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
      "                ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
      "                ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
      "                ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
      "                ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
      "                ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
      "                ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
      "                ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
      "                ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
      "                ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
      "                ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
      "                ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
      "                ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
      "                ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
      "                ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
      "                ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
      "                ('GO', 'GOING', 'SAY', 'SAYING'),\n",
      "                ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
      "                ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
      "                ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
      "                ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
      "                ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
      "                ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
      "                ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
      "                ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
      "                ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
      "                ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
      "                ('SAY', 'SAYING', 'GO', 'GOING'),\n",
      "                ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
      "                ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
      "                ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
      "                ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
      "                ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
      "                ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
      "                ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
      "                ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
      "                ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
      "                ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
      "                ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
      "                ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
      "                ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
      "                ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
      "                ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
      "                ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
      "                ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
      "                ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
      "                ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
      "                ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
      "                ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
      "                ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
      "                ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
      "                ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
      "                ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
      "                ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
      "                ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
      "                ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
      "                ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
      "                ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
      "                ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
      "                ('CAR', 'CARS', 'MAN', 'MEN'),\n",
      "                ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
      "                ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
      "                ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
      "                ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
      "                ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
      "                ('MAN', 'MEN', 'CAR', 'CARS')],\n",
      "  'section': 'total'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d85a41720ae0>:1: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.accuracy() instead).\n",
      "  print(model.accuracy(questions=datapath('questions-words.txt')))\n"
     ]
    }
   ],
   "source": [
    "print(model.accuracy(questions=datapath('questions-words.txt')))sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Movers distance\n",
    "\n",
    "Let’s start with two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove their stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "sentence_obama = [w for w in sentence_obama if w not in stopwords]\n",
    "sentence_president = [w for w in sentence_president if w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute WMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3940237954608796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-136d73d70ed4>:1: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
      "  distance = model.wmdistance(sentence_obama, sentence_president)\n"
     ]
    }
   ],
   "source": [
    "distance = model.wmdistance(sentence_obama, sentence_president)\n",
    "print(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
