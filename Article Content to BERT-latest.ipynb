{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'USER': 'fandav',\n",
       "        'JUPYTERHUB_HOST': '',\n",
       "        'LD_LIBRARY_PATH': '/usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu',\n",
       "        'JUPYTERHUB_USER': 'fandav',\n",
       "        'SHLVL': '0',\n",
       "        'HOME': '/home/fandav',\n",
       "        'JUPYTERHUB_API_URL': 'http://127.0.0.1:8081/hub/api',\n",
       "        'JUPYTERHUB_OAUTH_CALLBACK_URL': '/user/fandav/oauth_callback',\n",
       "        'SLURM': '1',\n",
       "        'JUPYTERHUB_CLIENT_ID': 'jupyterhub-user-fandav',\n",
       "        'PATH': '/home/fandav/.local/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/anaconda3/envs/jupyter/bin:/opt/anaconda3/bin/:/snap/bin',\n",
       "        'JUPYTERHUB_ACTIVITY_URL': 'http://127.0.0.1:8081/hub/api/users/fandav/activity',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'SHELL': '/bin/zsh',\n",
       "        'JUPYTERHUB_SERVICE_PREFIX': '/user/fandav/',\n",
       "        'PWD': '/home/fandav',\n",
       "        'JUPYTERHUB_API_TOKEN': 'fce9f2baebfc44f795960c829286241b',\n",
       "        'JUPYTERHUB_BASE_URL': '/',\n",
       "        'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop',\n",
       "        'JUPYTERHUB_SERVER_NAME': '',\n",
       "        'JPY_API_TOKEN': 'fce9f2baebfc44f795960c829286241b',\n",
       "        'KAPOHOBAY': '1',\n",
       "        'KERNEL_LAUNCH_TIMEOUT': '40',\n",
       "        'JPY_PARENT_PID': '24725',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       "        'CUDA_VISIBLE_DEVICES': '-1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU BEGONE!\n",
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu'\n",
    "os.environ['PATH'] = '/home/fandav/.local/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/anaconda3/envs/jupyter/bin:/opt/anaconda3/bin/:/snap/bin'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To find out which devices your operations and tensors are assigned to\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "=================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased');\n",
    "\n",
    "# model\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased');\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('final_dataset.csv', index_col=0)\n",
    "#display(dataset.loc['Content'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "(50, 512, 768)\n",
      "(50, 768)\n"
     ]
    }
   ],
   "source": [
    "# grab content\n",
    "dataset_content = dataset.loc['Content'].fillna('').values\n",
    "#print(dataset_content)\n",
    "\n",
    "# process content through BERT\n",
    "encoded_strings = [tokenizer.encode(content, max_length=512, pad_to_max_length=True) for content in dataset_content]\n",
    "encoded_vectors = tf.constant(encoded_strings)\n",
    "outputs = model(encoded_vectors)\n",
    "\n",
    "# obtain per line embeddings from all the artibles from BERT\n",
    "last_hidden_states = outputs[0]\n",
    "\n",
    "# obtain article embeddings from BERT\n",
    "article_embeddings = outputs[1]\n",
    "\n",
    "print(np.shape(outputs))\n",
    "print(np.shape(outputs[0]))\n",
    "print(np.shape(outputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_articles = np.shape(outputs)\n",
    "article_names = [f'Article {idx}' for idx in range(num_articles)]\n",
    "\n",
    "# vector embeddings of each article\n",
    "vec_embeddings = article_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final classifier labels\n",
    "credibility_label = np.array(list(map(int, dataset.loc['Credibility Score'].values)))\n",
    "\n",
    "# run NN with last layers changed to fit labels for each indicator\n",
    "indicators = [\n",
    "              'Originality Score',\n",
    "              'Fact-Checked',\n",
    "              'Attribution Rank',\n",
    "              'Source 1 Category',\n",
    "              'Source 2 Category',\n",
    "              'Source 3 Category',\n",
    "              'Article has Spammy/Clickbaity Ads',\n",
    "              'Article has Aggressive Ads/Calls'\n",
    "             ]\n",
    "\n",
    "indicator_data = []\n",
    "for truth_label in indicators:\n",
    "    label_values = np.array(np.array(list(map(int, dataset.loc[truth_label].values))))\n",
    "    indicator_data.append([label_values, len(label_values), set(label_values), len(set(label_values))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth label values</th>\n",
       "      <th>number of truth label values</th>\n",
       "      <th>unique truth labels</th>\n",
       "      <th>size of unique truth labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Originality Score</th>\n",
       "      <td>[0, 2, 0, 1, 3, 1, 0, 2, 0, 2, 2, 3, 0, 1, 2, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fact-Checked</th>\n",
       "      <td>[1, 2, 4, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 3, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3, 4}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribution Rank</th>\n",
       "      <td>[1, 2, 0, 1, 3, 1, 0, 2, 0, 2, 2, 3, 0, 4, 3, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3, 4}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 1 Category</th>\n",
       "      <td>[0, 2, 2, 0, 1, 3, 2, 2, 2, 0, 2, 2, 0, 3, 2, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 2 Category</th>\n",
       "      <td>[0, 1, 0, 0, 1, 3, 3, 2, 3, 0, 1, 2, 0, 3, 0, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 3 Category</th>\n",
       "      <td>[0, 1, 1, 0, 1, 3, 1, 2, 3, 0, 2, 2, 0, 3, 0, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article has Spammy/Clickbaity Ads</th>\n",
       "      <td>[2, 3, 1, 3, 2, 4, 4, 3, 4, 4, 2, 1, 2, 4, 3, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article has Aggressive Ads/Calls</th>\n",
       "      <td>[3, 3, 2, 4, 2, 3, 4, 4, 3, 4, 2, 1, 2, 4, 2, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  truth label values  \\\n",
       "Originality Score                  [0, 2, 0, 1, 3, 1, 0, 2, 0, 2, 2, 3, 0, 1, 2, ...   \n",
       "Fact-Checked                       [1, 2, 4, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 3, ...   \n",
       "Attribution Rank                   [1, 2, 0, 1, 3, 1, 0, 2, 0, 2, 2, 3, 0, 4, 3, ...   \n",
       "Source 1 Category                  [0, 2, 2, 0, 1, 3, 2, 2, 2, 0, 2, 2, 0, 3, 2, ...   \n",
       "Source 2 Category                  [0, 1, 0, 0, 1, 3, 3, 2, 3, 0, 1, 2, 0, 3, 0, ...   \n",
       "Source 3 Category                  [0, 1, 1, 0, 1, 3, 1, 2, 3, 0, 2, 2, 0, 3, 0, ...   \n",
       "Article has Spammy/Clickbaity Ads  [2, 3, 1, 3, 2, 4, 4, 3, 4, 4, 2, 1, 2, 4, 3, ...   \n",
       "Article has Aggressive Ads/Calls   [3, 3, 2, 4, 2, 3, 4, 4, 3, 4, 2, 1, 2, 4, 2, ...   \n",
       "\n",
       "                                   number of truth label values  \\\n",
       "Originality Score                                            50   \n",
       "Fact-Checked                                                 50   \n",
       "Attribution Rank                                             50   \n",
       "Source 1 Category                                            50   \n",
       "Source 2 Category                                            50   \n",
       "Source 3 Category                                            50   \n",
       "Article has Spammy/Clickbaity Ads                            50   \n",
       "Article has Aggressive Ads/Calls                             50   \n",
       "\n",
       "                                  unique truth labels  \\\n",
       "Originality Score                        {0, 1, 2, 3}   \n",
       "Fact-Checked                          {0, 1, 2, 3, 4}   \n",
       "Attribution Rank                      {0, 1, 2, 3, 4}   \n",
       "Source 1 Category                        {0, 1, 2, 3}   \n",
       "Source 2 Category                        {0, 1, 2, 3}   \n",
       "Source 3 Category                        {0, 1, 2, 3}   \n",
       "Article has Spammy/Clickbaity Ads  {0, 1, 2, 3, 4, 5}   \n",
       "Article has Aggressive Ads/Calls   {0, 1, 2, 3, 4, 5}   \n",
       "\n",
       "                                   size of unique truth labels  \n",
       "Originality Score                                            4  \n",
       "Fact-Checked                                                 5  \n",
       "Attribution Rank                                             5  \n",
       "Source 1 Category                                            4  \n",
       "Source 2 Category                                            4  \n",
       "Source 3 Category                                            4  \n",
       "Article has Spammy/Clickbaity Ads                            6  \n",
       "Article has Aggressive Ads/Calls                             6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indicators_df = pd.DataFrame(indicator_data,\n",
    "                             columns=['truth label values', 'number of truth label values', 'unique truth labels', 'size of unique truth labels'],\n",
    "                             index=indicators\n",
    "                            )\n",
    "display(indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article 43</th>\n",
       "      <th>Article 13</th>\n",
       "      <th>Article 14</th>\n",
       "      <th>Article 30</th>\n",
       "      <th>Article 23</th>\n",
       "      <th>Article 42</th>\n",
       "      <th>Article 49</th>\n",
       "      <th>Article 36</th>\n",
       "      <th>Article 45</th>\n",
       "      <th>Article 7</th>\n",
       "      <th>...</th>\n",
       "      <th>Article 44</th>\n",
       "      <th>Article 46</th>\n",
       "      <th>Article 35</th>\n",
       "      <th>Article 38</th>\n",
       "      <th>Article 37</th>\n",
       "      <th>Article 28</th>\n",
       "      <th>Article 29</th>\n",
       "      <th>Article 39</th>\n",
       "      <th>Article 41</th>\n",
       "      <th>Article 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>Which Banana Would You Eat? Your Answer May Ha...</td>\n",
       "      <td>NOW IT’S OFFICIAL: FDA Announced That Vaccines...</td>\n",
       "      <td>CONFIRMED: E-CIGARETTES CAUSE A HORRIBLE INCUR...</td>\n",
       "      <td>WITH ONLY 2 CUPS A DAY FOR 1 WEEK YOUR STOMACH...</td>\n",
       "      <td>Lead Developer of HPV Vaccines Comes Clean, Wa...</td>\n",
       "      <td>DELINGPOLE: Global Warming Study Cancelled Bec...</td>\n",
       "      <td>Diet drinks TRIPLE your risk of stroke and dem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nations Press: PLS SHARE: DO NOT EAT THIS FISH...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Opinion | How the Anti-Vaxxers Are Winning</td>\n",
       "      <td>Arctic’s Winter Sea Ice Drops to Its Lowest Re...</td>\n",
       "      <td>The Best Exercise for Aging Muscles</td>\n",
       "      <td>An Iceberg the Size of Delaware Just Broke Awa...</td>\n",
       "      <td>Putting Kids To Bed Early Improves Mom's Healt...</td>\n",
       "      <td>If Everyone Ate Beans Instead of Beef</td>\n",
       "      <td>Arctic stronghold of world’s seeds flooded aft...</td>\n",
       "      <td>The oldest child is actually the smartest, stu...</td>\n",
       "      <td>Coconut oil isn't healthy. It's never been hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Content</th>\n",
       "      <td>When we eat bananas, we do so because we are h...</td>\n",
       "      <td>The FDA has published conclusive proof on thei...</td>\n",
       "      <td>CONFIRMED: E-CIGARETTES CAUSE A HORRIBLE INCUR...</td>\n",
       "      <td>The desire of lots of people is to have a flat...</td>\n",
       "      <td>Lead Developer of HPV Vaccines Comes Clean, Wa...</td>\n",
       "      <td>A global warming research study in Canada has ...</td>\n",
       "      <td>The Boston University study of almost 4,400 ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A major measles outbreak in America is only a ...</td>\n",
       "      <td>Much of the ice also appears to be thinner tha...</td>\n",
       "      <td>Certain kinds of exercise may mitigate the eff...</td>\n",
       "      <td>A crack more than 120 miles long had developed...</td>\n",
       "      <td>A new study confirms why all those bedtime bat...</td>\n",
       "      <td>With one dietary change, the U.S. could hypoth...</td>\n",
       "      <td>No seeds were lost but the ability of the rock...</td>\n",
       "      <td>Birth order doesn't affect personality, but it...</td>\n",
       "      <td>“We advise against the use of coconut oil,\" th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URL</th>\n",
       "      <td>http://goodfullness.net/which-banana-would-you...</td>\n",
       "      <td>http://inshapetoday.com/now-official-fda-annou...</td>\n",
       "      <td>http://nowcheckthis.com/2017/03/23/confirmed-e...</td>\n",
       "      <td>http://publichealthabc.com/2-cups-day-1-week-s...</td>\n",
       "      <td>http://www.alternativenewsnetwork.net/lead-dev...</td>\n",
       "      <td>http://www.breitbart.com/big-government/2017/0...</td>\n",
       "      <td>http://www.dailymail.co.uk/~/article-4429790/i...</td>\n",
       "      <td>http://www.iflscience.com/environment/heavy-mo...</td>\n",
       "      <td>http://www.iflscience.com/health-and-medicine/...</td>\n",
       "      <td>http://www.nationspressph.com/2017/02/pls-shar...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.ntd.tv/inspiring/parenting/sam-ber...</td>\n",
       "      <td>https://www.nytimes.com/2017/02/08/opinion/how...</td>\n",
       "      <td>https://www.nytimes.com/2017/03/22/climate/arc...</td>\n",
       "      <td>https://www.nytimes.com/2017/03/23/well/move/t...</td>\n",
       "      <td>https://www.nytimes.com/interactive/2017/06/09...</td>\n",
       "      <td>https://www.simplemost.com/new-study-says-putt...</td>\n",
       "      <td>https://www.theatlantic.com/health/archive/201...</td>\n",
       "      <td>https://www.theguardian.com/environment/2017/m...</td>\n",
       "      <td>https://www.today.com/health/birth-order-first...</td>\n",
       "      <td>https://www.usatoday.com/story/news/nation-now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credibility Score</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Originality Score</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribution Rank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 1 Category</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 2 Category</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source 3 Category</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article has Spammy/Clickbaity Ads</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article has Aggressive Ads/Calls</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Content Recommendations</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Social Share Calls</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number Calls to Join Mailing List</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Ads</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Sponsored Content</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Article 43  \\\n",
       "Title                              Which Banana Would You Eat? Your Answer May Ha...   \n",
       "Content                            When we eat bananas, we do so because we are h...   \n",
       "URL                                http://goodfullness.net/which-banana-would-you...   \n",
       "Credibility Score                                                                  1   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   1   \n",
       "Source 1 Category                                                                  0   \n",
       "Source 2 Category                                                                  0   \n",
       "Source 3 Category                                                                  0   \n",
       "Article has Spammy/Clickbaity Ads                                                  2   \n",
       "Article has Aggressive Ads/Calls                                                   3   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                       2   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      3   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 13  \\\n",
       "Title                              NOW IT’S OFFICIAL: FDA Announced That Vaccines...   \n",
       "Content                            The FDA has published conclusive proof on thei...   \n",
       "URL                                http://inshapetoday.com/now-official-fda-annou...   \n",
       "Credibility Score                                                                  0   \n",
       "Originality Score                                                                  2   \n",
       "Attribution Rank                                                                   2   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  1   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  3   \n",
       "Article has Aggressive Ads/Calls                                                   3   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                       9   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      0   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 14  \\\n",
       "Title                              CONFIRMED: E-CIGARETTES CAUSE A HORRIBLE INCUR...   \n",
       "Content                            CONFIRMED: E-CIGARETTES CAUSE A HORRIBLE INCUR...   \n",
       "URL                                http://nowcheckthis.com/2017/03/23/confirmed-e...   \n",
       "Credibility Score                                                                  1   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  0   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  1   \n",
       "Article has Aggressive Ads/Calls                                                   2   \n",
       "Number of Content Recommendations                                                  0   \n",
       "Number of Social Share Calls                                                      10   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      0   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 30  \\\n",
       "Title                              WITH ONLY 2 CUPS A DAY FOR 1 WEEK YOUR STOMACH...   \n",
       "Content                            The desire of lots of people is to have a flat...   \n",
       "URL                                http://publichealthabc.com/2-cups-day-1-week-s...   \n",
       "Credibility Score                                                                  0   \n",
       "Originality Score                                                                  1   \n",
       "Attribution Rank                                                                   1   \n",
       "Source 1 Category                                                                  0   \n",
       "Source 2 Category                                                                  0   \n",
       "Source 3 Category                                                                  0   \n",
       "Article has Spammy/Clickbaity Ads                                                  3   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                      24   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      9   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 23  \\\n",
       "Title                              Lead Developer of HPV Vaccines Comes Clean, Wa...   \n",
       "Content                            Lead Developer of HPV Vaccines Comes Clean, Wa...   \n",
       "URL                                http://www.alternativenewsnetwork.net/lead-dev...   \n",
       "Credibility Score                                                                  0   \n",
       "Originality Score                                                                  3   \n",
       "Attribution Rank                                                                   3   \n",
       "Source 1 Category                                                                  1   \n",
       "Source 2 Category                                                                  1   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  2   \n",
       "Article has Aggressive Ads/Calls                                                   2   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                      10   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      0   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 42  \\\n",
       "Title                              DELINGPOLE: Global Warming Study Cancelled Bec...   \n",
       "Content                            A global warming research study in Canada has ...   \n",
       "URL                                http://www.breitbart.com/big-government/2017/0...   \n",
       "Credibility Score                                                                  1   \n",
       "Originality Score                                                                  1   \n",
       "Attribution Rank                                                                   1   \n",
       "Source 1 Category                                                                  3   \n",
       "Source 2 Category                                                                  3   \n",
       "Source 3 Category                                                                  3   \n",
       "Article has Spammy/Clickbaity Ads                                                  4   \n",
       "Article has Aggressive Ads/Calls                                                   3   \n",
       "Number of Content Recommendations                                                  3   \n",
       "Number of Social Share Calls                                                       5   \n",
       "Number Calls to Join Mailing List                                                  3   \n",
       "Number of Ads                                                                      1   \n",
       "Number of Sponsored Content                                                        1   \n",
       "\n",
       "                                                                          Article 49  \\\n",
       "Title                              Diet drinks TRIPLE your risk of stroke and dem...   \n",
       "Content                            The Boston University study of almost 4,400 ad...   \n",
       "URL                                http://www.dailymail.co.uk/~/article-4429790/i...   \n",
       "Credibility Score                                                                  1   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  3   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  4   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  8   \n",
       "Number of Social Share Calls                                                      14   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                     23   \n",
       "Number of Sponsored Content                                                        2   \n",
       "\n",
       "                                                                          Article 36  \\\n",
       "Title                                                                            NaN   \n",
       "Content                                                                          NaN   \n",
       "URL                                http://www.iflscience.com/environment/heavy-mo...   \n",
       "Credibility Score                                                                  0   \n",
       "Originality Score                                                                  2   \n",
       "Attribution Rank                                                                   2   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  2   \n",
       "Article has Spammy/Clickbaity Ads                                                  3   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  2   \n",
       "Number of Social Share Calls                                                       5   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      0   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 45  \\\n",
       "Title                                                                            NaN   \n",
       "Content                                                                          NaN   \n",
       "URL                                http://www.iflscience.com/health-and-medicine/...   \n",
       "Credibility Score                                                                  1   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  3   \n",
       "Source 3 Category                                                                  3   \n",
       "Article has Spammy/Clickbaity Ads                                                  4   \n",
       "Article has Aggressive Ads/Calls                                                   3   \n",
       "Number of Content Recommendations                                                  3   \n",
       "Number of Social Share Calls                                                       3   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      0   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                           Article 7  \\\n",
       "Title                              Nations Press: PLS SHARE: DO NOT EAT THIS FISH...   \n",
       "Content                                                                          NaN   \n",
       "URL                                http://www.nationspressph.com/2017/02/pls-shar...   \n",
       "Credibility Score                                                                  0   \n",
       "Originality Score                                                                  2   \n",
       "Attribution Rank                                                                   2   \n",
       "Source 1 Category                                                                  0   \n",
       "Source 2 Category                                                                  0   \n",
       "Source 3 Category                                                                  0   \n",
       "Article has Spammy/Clickbaity Ads                                                  4   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  3   \n",
       "Number of Social Share Calls                                                       6   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      4   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                   ...  \\\n",
       "Title                              ...   \n",
       "Content                            ...   \n",
       "URL                                ...   \n",
       "Credibility Score                  ...   \n",
       "Originality Score                  ...   \n",
       "Attribution Rank                   ...   \n",
       "Source 1 Category                  ...   \n",
       "Source 2 Category                  ...   \n",
       "Source 3 Category                  ...   \n",
       "Article has Spammy/Clickbaity Ads  ...   \n",
       "Article has Aggressive Ads/Calls   ...   \n",
       "Number of Content Recommendations  ...   \n",
       "Number of Social Share Calls       ...   \n",
       "Number Calls to Join Mailing List  ...   \n",
       "Number of Ads                      ...   \n",
       "Number of Sponsored Content        ...   \n",
       "\n",
       "                                                                          Article 44  \\\n",
       "Title                                                                            NaN   \n",
       "Content                                                                          NaN   \n",
       "URL                                https://www.ntd.tv/inspiring/parenting/sam-ber...   \n",
       "Credibility Score                                                                  2   \n",
       "Originality Score                                                                  2   \n",
       "Attribution Rank                                                                   3   \n",
       "Source 1 Category                                                                  3   \n",
       "Source 2 Category                                                                  3   \n",
       "Source 3 Category                                                                  3   \n",
       "Article has Spammy/Clickbaity Ads                                                  3   \n",
       "Article has Aggressive Ads/Calls                                                   2   \n",
       "Number of Content Recommendations                                                  3   \n",
       "Number of Social Share Calls                                                       2   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                      8   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 46  \\\n",
       "Title                                     Opinion | How the Anti-Vaxxers Are Winning   \n",
       "Content                            A major measles outbreak in America is only a ...   \n",
       "URL                                https://www.nytimes.com/2017/02/08/opinion/how...   \n",
       "Credibility Score                                                                  4   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  3   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  1   \n",
       "Article has Aggressive Ads/Calls                                                   1   \n",
       "Number of Content Recommendations                                                  2   \n",
       "Number of Social Share Calls                                                       3   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      2   \n",
       "Number of Sponsored Content                                                        1   \n",
       "\n",
       "                                                                          Article 35  \\\n",
       "Title                              Arctic’s Winter Sea Ice Drops to Its Lowest Re...   \n",
       "Content                            Much of the ice also appears to be thinner tha...   \n",
       "URL                                https://www.nytimes.com/2017/03/22/climate/arc...   \n",
       "Credibility Score                                                                  4   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  0   \n",
       "Article has Spammy/Clickbaity Ads                                                  0   \n",
       "Article has Aggressive Ads/Calls                                                   1   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                       3   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      2   \n",
       "Number of Sponsored Content                                                        1   \n",
       "\n",
       "                                                                          Article 38  \\\n",
       "Title                                            The Best Exercise for Aging Muscles   \n",
       "Content                            Certain kinds of exercise may mitigate the eff...   \n",
       "URL                                https://www.nytimes.com/2017/03/23/well/move/t...   \n",
       "Credibility Score                                                                  3   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  1   \n",
       "Source 3 Category                                                                  0   \n",
       "Article has Spammy/Clickbaity Ads                                                  0   \n",
       "Article has Aggressive Ads/Calls                                                   1   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                       5   \n",
       "Number Calls to Join Mailing List                                                  2   \n",
       "Number of Ads                                                                      2   \n",
       "Number of Sponsored Content                                                        1   \n",
       "\n",
       "                                                                          Article 37  \\\n",
       "Title                              An Iceberg the Size of Delaware Just Broke Awa...   \n",
       "Content                            A crack more than 120 miles long had developed...   \n",
       "URL                                https://www.nytimes.com/interactive/2017/06/09...   \n",
       "Credibility Score                                                                  4   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  3   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  0   \n",
       "Article has Aggressive Ads/Calls                                                   0   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                       5   \n",
       "Number Calls to Join Mailing List                                                  0   \n",
       "Number of Ads                                                                     12   \n",
       "Number of Sponsored Content                                                        0   \n",
       "\n",
       "                                                                          Article 28  \\\n",
       "Title                              Putting Kids To Bed Early Improves Mom's Healt...   \n",
       "Content                            A new study confirms why all those bedtime bat...   \n",
       "URL                                https://www.simplemost.com/new-study-says-putt...   \n",
       "Credibility Score                                                                  2   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  2   \n",
       "Article has Spammy/Clickbaity Ads                                                  4   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  8   \n",
       "Number of Social Share Calls                                                       5   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      4   \n",
       "Number of Sponsored Content                                                        2   \n",
       "\n",
       "                                                                          Article 29  \\\n",
       "Title                                          If Everyone Ate Beans Instead of Beef   \n",
       "Content                            With one dietary change, the U.S. could hypoth...   \n",
       "URL                                https://www.theatlantic.com/health/archive/201...   \n",
       "Credibility Score                                                                  4   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  3   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  2   \n",
       "Article has Spammy/Clickbaity Ads                                                  1   \n",
       "Article has Aggressive Ads/Calls                                                   2   \n",
       "Number of Content Recommendations                                                  2   \n",
       "Number of Social Share Calls                                                      11   \n",
       "Number Calls to Join Mailing List                                                  2   \n",
       "Number of Ads                                                                      2   \n",
       "Number of Sponsored Content                                                        2   \n",
       "\n",
       "                                                                          Article 39  \\\n",
       "Title                              Arctic stronghold of world’s seeds flooded aft...   \n",
       "Content                            No seeds were lost but the ability of the rock...   \n",
       "URL                                https://www.theguardian.com/environment/2017/m...   \n",
       "Credibility Score                                                                  4   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  3   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  2   \n",
       "Article has Spammy/Clickbaity Ads                                                  1   \n",
       "Article has Aggressive Ads/Calls                                                   1   \n",
       "Number of Content Recommendations                                                  1   \n",
       "Number of Social Share Calls                                                      11   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      6   \n",
       "Number of Sponsored Content                                                        1   \n",
       "\n",
       "                                                                          Article 41  \\\n",
       "Title                              The oldest child is actually the smartest, stu...   \n",
       "Content                            Birth order doesn't affect personality, but it...   \n",
       "URL                                https://www.today.com/health/birth-order-first...   \n",
       "Credibility Score                                                                  3   \n",
       "Originality Score                                                                  0   \n",
       "Attribution Rank                                                                   0   \n",
       "Source 1 Category                                                                  2   \n",
       "Source 2 Category                                                                  2   \n",
       "Source 3 Category                                                                  1   \n",
       "Article has Spammy/Clickbaity Ads                                                  3   \n",
       "Article has Aggressive Ads/Calls                                                   4   \n",
       "Number of Content Recommendations                                                  3   \n",
       "Number of Social Share Calls                                                      17   \n",
       "Number Calls to Join Mailing List                                                  1   \n",
       "Number of Ads                                                                      3   \n",
       "Number of Sponsored Content                                                        3   \n",
       "\n",
       "                                                                          Article 12  \n",
       "Title                              Coconut oil isn't healthy. It's never been hea...  \n",
       "Content                            “We advise against the use of coconut oil,\" th...  \n",
       "URL                                https://www.usatoday.com/story/news/nation-now...  \n",
       "Credibility Score                                                                  3  \n",
       "Originality Score                                                                  0  \n",
       "Attribution Rank                                                                   0  \n",
       "Source 1 Category                                                                  2  \n",
       "Source 2 Category                                                                  2  \n",
       "Source 3 Category                                                                  3  \n",
       "Article has Spammy/Clickbaity Ads                                                  2  \n",
       "Article has Aggressive Ads/Calls                                                   2  \n",
       "Number of Content Recommendations                                                  2  \n",
       "Number of Social Share Calls                                                      11  \n",
       "Number Calls to Join Mailing List                                                  2  \n",
       "Number of Ads                                                                      2  \n",
       "Number of Sponsored Content                                                        2  \n",
       "\n",
       "[16 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalMaxPooling1D, Conv1D, MaxPooling1D, InputLayer, Input, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def(last_layer_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(768, 1), name='input'),\n",
    "        \n",
    "        Conv1D(400, 3, padding='valid', activation='relu', strides=3, input_shape=(768,)),\n",
    "        Dense(200, activation='relu', name='dense_0'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        #Conv1D(200, 3, padding='valid', activation='relu', strides=3),\n",
    "        #Dense(150, activation='relu', name='dense_1'),\n",
    "        #Dropout(0.2),\n",
    "        \n",
    "        Conv1D(100, 3, padding='valid', activation='relu', strides=5),\n",
    "        GlobalMaxPooling1D(),\n",
    "        \n",
    "        Dense(64, activation='relu', name='dense_2'),\n",
    "        \n",
    "        #Dense(len(set(truth_labels)), name='dense_3', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        Dense(last_layer_size, name='dense_3', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        Softmax()\n",
    "    ]);\n",
    "    #model.summary()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer\n",
    "                  # Loss function to minimize\n",
    "                  #loss=tf.keras.losses.SquaredHinge(),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  # List of metrics to monitor\n",
    "                  metrics=['accuracy']);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x, y, epochs=300, batch_size=10, verbose=1):\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "def test_model(model, x, y, verbose=1):\n",
    "    test_loss, test_acc = model.evaluate(x,  y, verbose=verbose)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def predict(model, x):\n",
    "    # predict a few samples\n",
    "    output = model.predict(x)\n",
    "    print(f'Output Vector: \\n{output}')\n",
    "    print(f'Output Vector Rounded: \\n{np.round(output)}')\n",
    "    print('Output Label: {}'.format([np.where(r==1)[0][0] for r in np.round(output)]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndingLossAccCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print('Training: batch {}, Loss: {:.2f}, Accuracy: {:.2f}'.format(batch,  logs['loss'], logs['accuracy']))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print('Testing: batch {}, Loss: {:.2f}, Accuracy: {:.2f}'.format(batch,  logs['loss'], logs['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 768, 1)\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_192 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_193 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_96 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax_96 (Softmax)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 148,624\n",
      "Trainable params: 148,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_194 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_195 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_97 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "softmax_97 (Softmax)         (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 148,689\n",
      "Trainable params: 148,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_196 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_197 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_98 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "softmax_98 (Softmax)         (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 148,689\n",
      "Trainable params: 148,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_198 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_199 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_99 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax_99 (Softmax)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 148,624\n",
      "Trainable params: 148,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_200 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_201 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_100 (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax_100 (Softmax)        (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 148,624\n",
      "Trainable params: 148,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_202 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_203 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_101 (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax_101 (Softmax)        (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 148,624\n",
      "Trainable params: 148,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_204 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_205 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_102 (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "softmax_102 (Softmax)        (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 148,754\n",
      "Trainable params: 148,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_206 (Conv1D)          (None, 256, 400)          1600      \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 256, 200)          80200     \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 256, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_207 (Conv1D)          (None, 51, 100)           60100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_103 (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "softmax_103 (Softmax)        (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 148,754\n",
      "Trainable params: 148,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training: batch 0, Loss: 1.45, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.45, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.47, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.44, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.36, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.39, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.36, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.38, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.39, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.43, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.41, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.41, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.37\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.42, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.40, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.42, Accuracy: 0.39\n",
      "Training: batch 23, Loss: 1.42, Accuracy: 0.38\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.36, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.37, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.35, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.34, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.31, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.33, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.33, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.34, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.35, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.37, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.36, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.35, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.34, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.33, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.33, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.34, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.34, Accuracy: 0.47\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.14, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.39, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.45, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.37, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.24, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.34, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.38, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.33, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.33, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.36, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.38, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.35, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.37, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.34, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.36, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.38, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.36, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.37, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.35, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.35, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.33, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.32, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.34, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.32, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.33, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.32, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.33, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.32, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.30, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.30, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.31, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.30, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.28, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.28, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.28, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.28, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.78, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.38, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.44, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.35, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.40, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.44, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.50, Accuracy: 0.27\n",
      "Training: batch 11, Loss: 1.52, Accuracy: 0.25\n",
      "Training: batch 12, Loss: 1.47, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.49, Accuracy: 0.29\n",
      "Training: batch 14, Loss: 1.45, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.40, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.37, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.36, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.33, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.32, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.29, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.29, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.30, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.29, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.28, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.31, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.29, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.28, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.76, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.31, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.35, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.38, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.34, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.30, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.33, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.36, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.33, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.38, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.45, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.41, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.45, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.46, Accuracy: 0.29\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.44, Accuracy: 0.31\n",
      "Training: batch 16, Loss: 1.42, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.36, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.38, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.35, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.33, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.26, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.24, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.24, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.25, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.25, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.55, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.34, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.39, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.36, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.31, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.30, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.32, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.30, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.29, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.31, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.27, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.27, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.28, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.29, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.27, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.27, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.29, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.30, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.31, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.32, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.31, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.31, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.31, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.31, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.32, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.32, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.30, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.30, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.30, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.29, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.28, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.29, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.28, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.29, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.28, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.26, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.49, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.45, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.48, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.45, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.39, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.43, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.39, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.32, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.34, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.28, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.80, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.51, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.33, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.31, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.30, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.28, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.46, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.38, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.26, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.15, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.29, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.32, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.32, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.26, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.21, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.25, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.14, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.05, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.13, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.06, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.17, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.12, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.08, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.21, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.17, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.14, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.11, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.16, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.14, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.17, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.15, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.21, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.24, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.42, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.36, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.21, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.10, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.20, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.13, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.08, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.04, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.14, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.19, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.23, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.25, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.25, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.25, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.25, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.25, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.40, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.52, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.34, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.44, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.46, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.43, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.41, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.26, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.30, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.33, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.29, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.35, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.37, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.38, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.35, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.32, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.27, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.32, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.30, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.28, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.25, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.25, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.05, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.22, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.23, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.24, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.24, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.25, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.25, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.26, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.25, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.23, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.23, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.23, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.03, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 0.99, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 0.97, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 0.95, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.03, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.04, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.12, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.45, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.27, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.18, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.23, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.19, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.47, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.41, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.33, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.26, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.29, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.24, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.26, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.23, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.21, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.23, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.24, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.22, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.24, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.21, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.24, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.22, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.54, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.63, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.36, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.17, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.11, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.07, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.14, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.17, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.26, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.26, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.23, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.24, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.27, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.29, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.26, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.21, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.21, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.28, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.55, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.39, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.25, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.27, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.21, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.22, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 36, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.81, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.81, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.04, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.99, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.02, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 0.99, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 23, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.84, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.82, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.02, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.89, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.82, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.80, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.27, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.31, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.26, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.55, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.95, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.31, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.14, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 0.94, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 12, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 0.98, Accuracy: 0.79\n",
      "Training: batch 14, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 15, Loss: 0.95, Accuracy: 0.81\n",
      "Training: batch 16, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 0.97, Accuracy: 0.79\n",
      "Training: batch 19, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 20, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 22, Loss: 1.02, Accuracy: 0.74\n",
      "Training: batch 23, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 24, Loss: 1.04, Accuracy: 0.72\n",
      "Training: batch 25, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 26, Loss: 1.02, Accuracy: 0.74\n",
      "Training: batch 27, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 28, Loss: 1.03, Accuracy: 0.72\n",
      "Training: batch 29, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.18, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.07, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.21, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.22, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.63, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.47, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.29, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.27, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.28, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.37, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.32, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.27, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.91, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.89, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.87, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.97, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 36, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.18, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.37, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.04, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 0.98, Accuracy: 0.79\n",
      "Training: batch 14, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.83, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.13, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.04, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.34, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.32, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.13, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.25, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.26, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.39, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.07, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 0.96, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.16, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.27, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.27, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.78, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.80, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.79, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.79, Accuracy: 1.00\n",
      "Training: batch 6, Loss: 0.92, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.90, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.99, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 0.95, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 0.94, Accuracy: 0.83\n",
      "Training: batch 12, Loss: 0.92, Accuracy: 0.85\n",
      "Training: batch 13, Loss: 0.91, Accuracy: 0.86\n",
      "Training: batch 14, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 15, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.04, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.67, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.04, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.01, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 0.98, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 0.96, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 0.96, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 1.01, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 0.99, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.04, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.05, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 28, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 29, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.78, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.90, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.88, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.86, Accuracy: 0.89\n",
      "Training: batch 9, Loss: 0.85, Accuracy: 0.90\n",
      "Training: batch 10, Loss: 0.93, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.91, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.27, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.27, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.27, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.44, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.35, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.39, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.32, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.28, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.07, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.36, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.17, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.11, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.07, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.04, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.45, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.37, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.27, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.29, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 36, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 42, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 43, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 44, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.09, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.04, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.21, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.23, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.23, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.19, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.19, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.39, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.44, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.22\n",
      "Training: batch 9, Loss: 1.40, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.34, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.37, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.33, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.36, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.38, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.36, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.32, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.31, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.33, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.30, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.30, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.28, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.25, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.37, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.25, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.16, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.10, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.06, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.14, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.10, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.14, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.11, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.09, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.10, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.08, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.07, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.07, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.07, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 37, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.64, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.69, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.38, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.47, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.52, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.38, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.38, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.32, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.27, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.26, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.29, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.31, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.31, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.29, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.25, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.91, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.12, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.09, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.03, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.12, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.05, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.13, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.12, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.93, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.91, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.89, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.87, Accuracy: 0.89\n",
      "Training: batch 9, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 0.94, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.13, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.10, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.08, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.10, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.90, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.88, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 0.99, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 1.02, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 0.99, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 22, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 23, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 24, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 36, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 38, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 40, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.78, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.15, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.17, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.06, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.04, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 1.02, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 1.01, Accuracy: 0.77\n",
      "Training: batch 22, Loss: 1.04, Accuracy: 0.74\n",
      "Training: batch 23, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 24, Loss: 1.06, Accuracy: 0.72\n",
      "Training: batch 25, Loss: 1.05, Accuracy: 0.73\n",
      "Training: batch 26, Loss: 1.04, Accuracy: 0.74\n",
      "Training: batch 27, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 28, Loss: 1.05, Accuracy: 0.72\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.70\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 31, Loss: 1.06, Accuracy: 0.72\n",
      "Training: batch 32, Loss: 1.08, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 34, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 35, Loss: 1.05, Accuracy: 0.72\n",
      "Training: batch 36, Loss: 1.04, Accuracy: 0.73\n",
      "Training: batch 37, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 38, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 39, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 40, Loss: 1.10, Accuracy: 0.68\n",
      "Training: batch 41, Loss: 1.09, Accuracy: 0.69\n",
      "Training: batch 42, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 43, Loss: 1.12, Accuracy: 0.66\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.13, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.76, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.89, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.86, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.99, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 0.96, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.05, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.15, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.11, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.09, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.21, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.16, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.14, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.09, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 0.98, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.03, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.13, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.08, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.04, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.05, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.03, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.18, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.23, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.25, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.26, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.28, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.26, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.25, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.23, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.22, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.20, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.31, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.34, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.38, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.36, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.39, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.39, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.36, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.33, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.30, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.29, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.33, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 1.02, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 22, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 23, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 24, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 25, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 26, Loss: 1.03, Accuracy: 0.74\n",
      "Training: batch 27, Loss: 1.02, Accuracy: 0.75\n",
      "Training: batch 28, Loss: 1.04, Accuracy: 0.72\n",
      "Training: batch 29, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 30, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 31, Loss: 1.05, Accuracy: 0.72\n",
      "Training: batch 32, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 34, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 35, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 36, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.48, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.19, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.21, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.15, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.14, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.13, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.15, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.12, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 0.98, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.01, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 0.98, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 0.97, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 0.96, Accuracy: 0.79\n",
      "Training: batch 19, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 0.99, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 0.98, Accuracy: 0.77\n",
      "Training: batch 22, Loss: 0.97, Accuracy: 0.78\n",
      "Training: batch 23, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 24, Loss: 1.03, Accuracy: 0.72\n",
      "Training: batch 25, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 26, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 36, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 37, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 38, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 40, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 42, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 43, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.90, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.88, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.87, Accuracy: 0.89\n",
      "Training: batch 9, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.07, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 6, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 7, Loss: 0.87, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 0.86, Accuracy: 0.89\n",
      "Training: batch 9, Loss: 0.85, Accuracy: 0.90\n",
      "Training: batch 10, Loss: 0.84, Accuracy: 0.91\n",
      "Training: batch 11, Loss: 0.92, Accuracy: 0.83\n",
      "Training: batch 12, Loss: 0.90, Accuracy: 0.85\n",
      "Training: batch 13, Loss: 0.89, Accuracy: 0.86\n",
      "Training: batch 14, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 15, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 0.98, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 1.01, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.00, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 1.02, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.01, Accuracy: 0.73\n",
      "Training: batch 22, Loss: 1.00, Accuracy: 0.74\n",
      "Training: batch 23, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 24, Loss: 1.02, Accuracy: 0.72\n",
      "Training: batch 25, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 6, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 7, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 8, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 9, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 10, Loss: 0.86, Accuracy: 0.91\n",
      "Training: batch 11, Loss: 0.93, Accuracy: 0.83\n",
      "Training: batch 12, Loss: 0.92, Accuracy: 0.85\n",
      "Training: batch 13, Loss: 0.91, Accuracy: 0.86\n",
      "Training: batch 14, Loss: 0.89, Accuracy: 0.87\n",
      "Training: batch 15, Loss: 0.95, Accuracy: 0.81\n",
      "Training: batch 16, Loss: 0.94, Accuracy: 0.82\n",
      "Training: batch 17, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 0.97, Accuracy: 0.79\n",
      "Training: batch 19, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 1.00, Accuracy: 0.76\n",
      "Training: batch 21, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 22, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 23, Loss: 0.97, Accuracy: 0.79\n",
      "Training: batch 24, Loss: 0.96, Accuracy: 0.80\n",
      "Training: batch 25, Loss: 0.99, Accuracy: 0.77\n",
      "Training: batch 26, Loss: 0.98, Accuracy: 0.78\n",
      "Training: batch 27, Loss: 0.98, Accuracy: 0.79\n",
      "Training: batch 28, Loss: 0.97, Accuracy: 0.79\n",
      "Training: batch 29, Loss: 1.00, Accuracy: 0.77\n",
      "Training: batch 30, Loss: 1.02, Accuracy: 0.74\n",
      "Training: batch 31, Loss: 1.04, Accuracy: 0.72\n",
      "Training: batch 32, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 36, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 1.07, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.85, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.83, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 1.01, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.97, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 0.93, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 0.91, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 1.00, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.08, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.05, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.08, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.06, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.04, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.49, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.49, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.53, Accuracy: 0.17\n",
      "Training: batch 6, Loss: 1.56, Accuracy: 0.14\n",
      "Training: batch 7, Loss: 1.46, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.38, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.31, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.26, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.26, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.25, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.24, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.24, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.94, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.91, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 40, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.31, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.13, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.08, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.08, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.55, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.58, Accuracy: 0.17\n",
      "Training: batch 6, Loss: 1.46, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.37, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.29, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.29, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 1.69, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.48, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.53, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.28, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.23, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.21, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.22, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.14, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.12, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.07, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.04, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.11, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.15, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.20, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.17, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.09, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.20, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 37, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 40, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 41, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 42, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 43, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 44, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 45, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 46, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.01, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.17, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.06, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.20, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.17, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.22, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.23, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.30, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.24, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.02, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.01, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 36, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 38, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 40, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 41, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 42, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 43, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 44, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.10, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.16, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.12, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.08, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.05, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.11, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.16, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.17, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.22, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.22, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 34, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 35, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 36, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 38, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 40, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 41, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 42, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 43, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 44, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 45, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 46, Loss: 1.09, Accuracy: 0.66\n",
      "Training: batch 47, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.54, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.19, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.20, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.22, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.21, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.77, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.17, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.21, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.13, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.08, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.23, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.14, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.09, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.14, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.16, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.20, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.09, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.07, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.05, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.07, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.11, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 29, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.09, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.11, Accuracy: 0.66\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 41, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.11, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 6, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 7, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 8, Loss: 0.85, Accuracy: 0.89\n",
      "Training: batch 9, Loss: 0.84, Accuracy: 0.90\n",
      "Training: batch 10, Loss: 0.92, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 0.97, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.01, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.03, Accuracy: 0.69\n",
      "Training: batch 16, Loss: 1.01, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.00, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 0.98, Accuracy: 0.74\n",
      "Training: batch 19, Loss: 1.02, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.05, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.05, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.07, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.87, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.81, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.12, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.03, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 0.93, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.02, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 0.99, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 0.97, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 0.95, Accuracy: 0.82\n",
      "Training: batch 11, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.03, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 1.05, Accuracy: 0.71\n",
      "Training: batch 17, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 20, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.20, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.17, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.06, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.03, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.20, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.23, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.32, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.29, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.26, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.28, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.28, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.27, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.29, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.28, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.27, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.28, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.26, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.23, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.21, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.19, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.25, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.30, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.25, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.24, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.18, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.41, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.30, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.22, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.29, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.23, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.18, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.23, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.16, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.15, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.10, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.12, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 28, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 29, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 30, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.06, Accuracy: 0.70\n",
      "Training: batch 33, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 34, Loss: 1.07, Accuracy: 0.69\n",
      "Training: batch 35, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 36, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 38, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 39, Loss: 1.08, Accuracy: 0.68\n",
      "Training: batch 40, Loss: 1.10, Accuracy: 0.66\n",
      "Training: batch 41, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 42, Loss: 1.11, Accuracy: 0.65\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.12, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.61, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.44, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.32, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.24, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.18, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.13, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.15, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.12, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.17, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.11, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.15, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.18, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.16, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.14, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.15, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.09, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 35, Loss: 1.08, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.09, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.98, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.23, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.35, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.23, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.31, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.24, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.18, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.14, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.25, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.18, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.22, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.19, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.17, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.17, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 47, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.75, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.24, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 0.99, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.01, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 0.98, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 0.97, Accuracy: 0.78\n",
      "Training: batch 18, Loss: 0.96, Accuracy: 0.79\n",
      "Training: batch 19, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 20, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 21, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 22, Loss: 1.05, Accuracy: 0.70\n",
      "Training: batch 23, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 24, Loss: 1.07, Accuracy: 0.68\n",
      "Training: batch 25, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 26, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 27, Loss: 1.03, Accuracy: 0.71\n",
      "Training: batch 28, Loss: 1.02, Accuracy: 0.72\n",
      "Training: batch 29, Loss: 1.04, Accuracy: 0.70\n",
      "Training: batch 30, Loss: 1.06, Accuracy: 0.68\n",
      "Training: batch 31, Loss: 1.05, Accuracy: 0.69\n",
      "Training: batch 32, Loss: 1.07, Accuracy: 0.67\n",
      "Training: batch 33, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 34, Loss: 1.08, Accuracy: 0.66\n",
      "Training: batch 35, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 36, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.10, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.09, Accuracy: 0.64\n",
      "Training: batch 39, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.01, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.04, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.00, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 0.97, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 0.95, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 1.02, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.06, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.08, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.10, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.09, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.09, Accuracy: 0.67\n",
      "Training: batch 27, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.17, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.15, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.16, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.67, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.69, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.46, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.52, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.39, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.30, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.29, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.24, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.28, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.24, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.24, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.20, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.24, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.21, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.18, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.16, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.13, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.16, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.14, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.11, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.10, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.12, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.11, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.13, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.15, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.13, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.12, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.14, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.16, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.15, Accuracy: 0.59\n",
      "Training: batch 44, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 45, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 46, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.14, Accuracy: 0.60\n",
      "Training: batch 48, Loss: 1.13, Accuracy: 0.61\n",
      "Training: batch 0, Loss: 0.79, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.26, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.42, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.50, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.32, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.31, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.29, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.22, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.23, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.21, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.19, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.21, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.19, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.18, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.15, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.18, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.17, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.16, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.12, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 42, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 43, Loss: 1.14, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.13, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 46, Loss: 1.11, Accuracy: 0.64\n",
      "Training: batch 47, Loss: 1.10, Accuracy: 0.65\n",
      "Training: batch 48, Loss: 1.12, Accuracy: 0.63\n",
      "Training: batch 0, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.71, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.71, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.71, Accuracy: 0.00\n",
      "Training: batch 5, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 6, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 7, Loss: 1.71, Accuracy: 0.00\n",
      "Training: batch 8, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 9, Loss: 1.70, Accuracy: 0.00\n",
      "Training: batch 10, Loss: 1.70, Accuracy: 0.09\n",
      "Training: batch 11, Loss: 1.69, Accuracy: 0.08\n",
      "Training: batch 12, Loss: 1.69, Accuracy: 0.08\n",
      "Training: batch 13, Loss: 1.69, Accuracy: 0.07\n",
      "Training: batch 14, Loss: 1.68, Accuracy: 0.13\n",
      "Training: batch 15, Loss: 1.67, Accuracy: 0.19\n",
      "Training: batch 16, Loss: 1.65, Accuracy: 0.24\n",
      "Training: batch 17, Loss: 1.66, Accuracy: 0.22\n",
      "Training: batch 18, Loss: 1.67, Accuracy: 0.21\n",
      "Training: batch 19, Loss: 1.66, Accuracy: 0.25\n",
      "Training: batch 20, Loss: 1.64, Accuracy: 0.29\n",
      "Training: batch 21, Loss: 1.65, Accuracy: 0.27\n",
      "Training: batch 22, Loss: 1.63, Accuracy: 0.30\n",
      "Training: batch 23, Loss: 1.65, Accuracy: 0.29\n",
      "Training: batch 24, Loss: 1.65, Accuracy: 0.28\n",
      "Training: batch 25, Loss: 1.64, Accuracy: 0.31\n",
      "Training: batch 26, Loss: 1.64, Accuracy: 0.30\n",
      "Training: batch 27, Loss: 1.65, Accuracy: 0.29\n",
      "Training: batch 28, Loss: 1.65, Accuracy: 0.28\n",
      "Training: batch 29, Loss: 1.64, Accuracy: 0.30\n",
      "Training: batch 30, Loss: 1.63, Accuracy: 0.32\n",
      "Training: batch 31, Loss: 1.62, Accuracy: 0.34\n",
      "Training: batch 32, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 33, Loss: 1.63, Accuracy: 0.32\n",
      "Training: batch 34, Loss: 1.64, Accuracy: 0.31\n",
      "Training: batch 35, Loss: 1.65, Accuracy: 0.31\n",
      "Training: batch 36, Loss: 1.64, Accuracy: 0.32\n",
      "Training: batch 37, Loss: 1.62, Accuracy: 0.34\n",
      "Training: batch 38, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 39, Loss: 1.64, Accuracy: 0.32\n",
      "Training: batch 40, Loss: 1.64, Accuracy: 0.32\n",
      "Training: batch 41, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 42, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 43, Loss: 1.64, Accuracy: 0.32\n",
      "Training: batch 44, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 45, Loss: 1.64, Accuracy: 0.33\n",
      "Training: batch 46, Loss: 1.64, Accuracy: 0.32\n",
      "Training: batch 47, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 48, Loss: 1.63, Accuracy: 0.33\n",
      "Training: batch 0, Loss: 1.89, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.57, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.68, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.71, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.61, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.52, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.57, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.51, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.51, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.46, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.43, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.47, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.50, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.47, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.49, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.47, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.39, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.42, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.44, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.47, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.50, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.52, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.50, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.52, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.50, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.49, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.51, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.52, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.53, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.55, Accuracy: 0.42\n",
      "Training: batch 36, Loss: 1.55, Accuracy: 0.41\n",
      "Training: batch 37, Loss: 1.54, Accuracy: 0.42\n",
      "Training: batch 38, Loss: 1.54, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 40, Loss: 1.53, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.52, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.53, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.55, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.54, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.54, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.08, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.04, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.33, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.54, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.59, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.62, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.57, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.53, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.52, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.44, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.50, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.54, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.52, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.42, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.42, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.48, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.51, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.52, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.47, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.47, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.47, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.47, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.47, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.46, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.47, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.52, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.17, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.64, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.65, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.59, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.53, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.57, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.60, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.61, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.58, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.54, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.51, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.53, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.55, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.42, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.42, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.44, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.47, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.51, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.49, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.50, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.49, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.47, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.51, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.97, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.51, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.60, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.55, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.47, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.51, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.88, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.85, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.80, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.67, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.70, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.61, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.64, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.57, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.60, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.54, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.57, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.53, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.42, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.39, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.36, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.46, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.46, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.46, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.48, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.52, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.50, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.48, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.51, Accuracy: 0.42\n",
      "Training: batch 48, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.79, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.50, Accuracy: 0.39\n",
      "Training: batch 23, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 29, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 30, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 31, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 32, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 33, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 34, Loss: 1.54, Accuracy: 0.37\n",
      "Training: batch 35, Loss: 1.53, Accuracy: 0.39\n",
      "Training: batch 36, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 37, Loss: 1.54, Accuracy: 0.37\n",
      "Training: batch 38, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 40, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 41, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 42, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.51, Accuracy: 0.41\n",
      "Training: batch 44, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.79, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.53, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.57, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 14, Loss: 1.58, Accuracy: 0.27\n",
      "Training: batch 15, Loss: 1.60, Accuracy: 0.25\n",
      "Training: batch 16, Loss: 1.58, Accuracy: 0.29\n",
      "Training: batch 17, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.57, Accuracy: 0.32\n",
      "Training: batch 19, Loss: 1.58, Accuracy: 0.30\n",
      "Training: batch 20, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 21, Loss: 1.56, Accuracy: 0.32\n",
      "Training: batch 22, Loss: 1.57, Accuracy: 0.30\n",
      "Training: batch 23, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 24, Loss: 1.57, Accuracy: 0.28\n",
      "Training: batch 25, Loss: 1.56, Accuracy: 0.31\n",
      "Training: batch 26, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 27, Loss: 1.55, Accuracy: 0.32\n",
      "Training: batch 28, Loss: 1.56, Accuracy: 0.31\n",
      "Training: batch 29, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 30, Loss: 1.55, Accuracy: 0.32\n",
      "Training: batch 31, Loss: 1.54, Accuracy: 0.34\n",
      "Training: batch 32, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 33, Loss: 1.54, Accuracy: 0.35\n",
      "Training: batch 34, Loss: 1.55, Accuracy: 0.34\n",
      "Training: batch 35, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 36, Loss: 1.55, Accuracy: 0.35\n",
      "Training: batch 37, Loss: 1.53, Accuracy: 0.37\n",
      "Training: batch 38, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 41, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.75, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.81, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.78, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.74, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.63, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.63, Accuracy: 0.17\n",
      "Training: batch 6, Loss: 1.66, Accuracy: 0.14\n",
      "Training: batch 7, Loss: 1.60, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.60, Accuracy: 0.22\n",
      "Training: batch 9, Loss: 1.56, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 48, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 0, Loss: 1.36, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.33, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.28, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 1.33, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.30, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.38, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.34, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.40, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.36, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.40, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.45, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.51, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.53, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.53, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.54, Accuracy: 0.36\n",
      "Training: batch 22, Loss: 1.55, Accuracy: 0.35\n",
      "Training: batch 23, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 24, Loss: 1.54, Accuracy: 0.36\n",
      "Training: batch 25, Loss: 1.55, Accuracy: 0.35\n",
      "Training: batch 26, Loss: 1.54, Accuracy: 0.37\n",
      "Training: batch 27, Loss: 1.55, Accuracy: 0.36\n",
      "Training: batch 28, Loss: 1.54, Accuracy: 0.38\n",
      "Training: batch 29, Loss: 1.53, Accuracy: 0.40\n",
      "Training: batch 30, Loss: 1.52, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.52, Accuracy: 0.41\n",
      "Training: batch 32, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 33, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 34, Loss: 1.54, Accuracy: 0.37\n",
      "Training: batch 35, Loss: 1.53, Accuracy: 0.39\n",
      "Training: batch 36, Loss: 1.52, Accuracy: 0.41\n",
      "Training: batch 37, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 38, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 40, Loss: 1.52, Accuracy: 0.37\n",
      "Training: batch 41, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 42, Loss: 1.51, Accuracy: 0.37\n",
      "Training: batch 43, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 44, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 45, Loss: 1.50, Accuracy: 0.37\n",
      "Training: batch 46, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 47, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 48, Loss: 1.48, Accuracy: 0.41\n",
      "Training: batch 0, Loss: 1.87, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.77, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.80, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.64, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.63, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.51, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 36, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 38, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 39, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 41, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.05, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.32, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.58, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.51, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.53, Accuracy: 0.37\n",
      "Training: batch 27, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 30, Loss: 1.51, Accuracy: 0.39\n",
      "Training: batch 31, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 32, Loss: 1.50, Accuracy: 0.39\n",
      "Training: batch 33, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 34, Loss: 1.52, Accuracy: 0.37\n",
      "Training: batch 35, Loss: 1.51, Accuracy: 0.39\n",
      "Training: batch 36, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 37, Loss: 1.51, Accuracy: 0.39\n",
      "Training: batch 38, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 41, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.66, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.22, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.18, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.30, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.38, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.39, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.40, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.52, Accuracy: 0.37\n",
      "Training: batch 27, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 28, Loss: 1.53, Accuracy: 0.34\n",
      "Training: batch 29, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 30, Loss: 1.52, Accuracy: 0.35\n",
      "Training: batch 31, Loss: 1.52, Accuracy: 0.34\n",
      "Training: batch 32, Loss: 1.51, Accuracy: 0.33\n",
      "Training: batch 33, Loss: 1.51, Accuracy: 0.32\n",
      "Training: batch 34, Loss: 1.50, Accuracy: 0.31\n",
      "Training: batch 35, Loss: 1.50, Accuracy: 0.33\n",
      "Training: batch 36, Loss: 1.49, Accuracy: 0.35\n",
      "Training: batch 37, Loss: 1.49, Accuracy: 0.34\n",
      "Training: batch 38, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 39, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 40, Loss: 1.48, Accuracy: 0.37\n",
      "Training: batch 41, Loss: 1.49, Accuracy: 0.36\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.37\n",
      "Training: batch 43, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 45, Loss: 1.48, Accuracy: 0.37\n",
      "Training: batch 46, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 47, Loss: 1.48, Accuracy: 0.38\n",
      "Training: batch 48, Loss: 1.47, Accuracy: 0.39\n",
      "Training: batch 0, Loss: 1.86, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.87, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.61, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.60, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.50, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.49, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.47, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.42, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.46, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 48, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 0, Loss: 1.07, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.04, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.32, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.24, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.31, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.39, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.34, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.39, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.36, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.33, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.37, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.40, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 34, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 35, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 36, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 48, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.86, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.55, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.38, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.30, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.41, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.43, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.37, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.42, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.43, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.42, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.48, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.42, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.47, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.42, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 48, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 0, Loss: 1.04, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.45, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.40, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.38, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.35, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.33, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.36, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.36, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.36, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.39, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.41, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.42, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.43, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.45, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.81, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.85, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.85, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.85, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.72, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.59, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.61, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.64, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.54, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.51, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.47, Accuracy: 0.39\n",
      "Training: batch 23, Loss: 1.46, Accuracy: 0.38\n",
      "Training: batch 24, Loss: 1.46, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.48, Accuracy: 0.37\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.36\n",
      "Training: batch 28, Loss: 1.49, Accuracy: 0.34\n",
      "Training: batch 29, Loss: 1.50, Accuracy: 0.33\n",
      "Training: batch 30, Loss: 1.49, Accuracy: 0.35\n",
      "Training: batch 31, Loss: 1.50, Accuracy: 0.34\n",
      "Training: batch 32, Loss: 1.49, Accuracy: 0.36\n",
      "Training: batch 33, Loss: 1.48, Accuracy: 0.38\n",
      "Training: batch 34, Loss: 1.49, Accuracy: 0.37\n",
      "Training: batch 35, Loss: 1.50, Accuracy: 0.36\n",
      "Training: batch 36, Loss: 1.50, Accuracy: 0.35\n",
      "Training: batch 37, Loss: 1.49, Accuracy: 0.37\n",
      "Training: batch 38, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 40, Loss: 1.48, Accuracy: 0.39\n",
      "Training: batch 41, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 42, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 43, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 44, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 45, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 46, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 0.99, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.39\n",
      "Training: batch 23, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 32, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.42, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.42, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.42, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.43, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.86, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.87, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.86, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.73, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.66, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.49, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.49, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.45, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.00, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.20, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.17, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.13, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.46, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.45, Accuracy: 0.41\n",
      "Training: batch 34, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.42\n",
      "Training: batch 36, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.42\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 39, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.46, Accuracy: 0.39\n",
      "Training: batch 41, Loss: 1.46, Accuracy: 0.40\n",
      "Training: batch 42, Loss: 1.44, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 48, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 0, Loss: 1.84, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.45, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.45, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.39, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.36, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.38, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.38, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.38, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.42, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.45, Accuracy: 0.29\n",
      "Training: batch 14, Loss: 1.44, Accuracy: 0.27\n",
      "Training: batch 15, Loss: 1.44, Accuracy: 0.25\n",
      "Training: batch 16, Loss: 1.41, Accuracy: 0.29\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.41, Accuracy: 0.32\n",
      "Training: batch 19, Loss: 1.44, Accuracy: 0.30\n",
      "Training: batch 20, Loss: 1.45, Accuracy: 0.29\n",
      "Training: batch 21, Loss: 1.43, Accuracy: 0.32\n",
      "Training: batch 22, Loss: 1.41, Accuracy: 0.35\n",
      "Training: batch 23, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.36\n",
      "Training: batch 25, Loss: 1.40, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.40, Accuracy: 0.37\n",
      "Training: batch 27, Loss: 1.38, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.40, Accuracy: 0.38\n",
      "Training: batch 29, Loss: 1.42, Accuracy: 0.37\n",
      "Training: batch 30, Loss: 1.43, Accuracy: 0.35\n",
      "Training: batch 31, Loss: 1.42, Accuracy: 0.38\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.39\n",
      "Training: batch 33, Loss: 1.42, Accuracy: 0.38\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.37\n",
      "Training: batch 35, Loss: 1.42, Accuracy: 0.39\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.38\n",
      "Training: batch 37, Loss: 1.42, Accuracy: 0.39\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.38\n",
      "Training: batch 39, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.43, Accuracy: 0.39\n",
      "Training: batch 41, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 42, Loss: 1.41, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.42, Accuracy: 0.41\n",
      "Training: batch 44, Loss: 1.43, Accuracy: 0.40\n",
      "Training: batch 45, Loss: 1.42, Accuracy: 0.41\n",
      "Training: batch 46, Loss: 1.41, Accuracy: 0.43\n",
      "Training: batch 47, Loss: 1.42, Accuracy: 0.42\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.43\n",
      "Training: batch 0, Loss: 1.06, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.01, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.97, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.23, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.25, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.24, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.34, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.38, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.35, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.34, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.36, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.36, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.34, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.03, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.31, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.22, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.55, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.61, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.54, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.58, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.53, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.54, Accuracy: 0.31\n",
      "Training: batch 16, Loss: 1.54, Accuracy: 0.29\n",
      "Training: batch 17, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.54, Accuracy: 0.32\n",
      "Training: batch 19, Loss: 1.51, Accuracy: 0.35\n",
      "Training: batch 20, Loss: 1.51, Accuracy: 0.33\n",
      "Training: batch 21, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 22, Loss: 1.50, Accuracy: 0.35\n",
      "Training: batch 23, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 24, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.45, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.46, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 45, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 48, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.33, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.30, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.27, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.34, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.88, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.24, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.19, Accuracy: 0.75\n",
      "Training: batch 12, Loss: 1.16, Accuracy: 0.77\n",
      "Training: batch 13, Loss: 1.15, Accuracy: 0.79\n",
      "Training: batch 14, Loss: 1.20, Accuracy: 0.73\n",
      "Training: batch 15, Loss: 1.18, Accuracy: 0.75\n",
      "Training: batch 16, Loss: 1.16, Accuracy: 0.76\n",
      "Training: batch 17, Loss: 1.20, Accuracy: 0.72\n",
      "Training: batch 18, Loss: 1.24, Accuracy: 0.68\n",
      "Training: batch 19, Loss: 1.27, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.29, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 0, Loss: 1.03, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.00, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.09, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.30, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.22, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 46, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 0, Loss: 0.99, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.96, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.96, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.10, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.08, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 1.18, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.22, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 43, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 44, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 45, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.04, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.55, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.62, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.73, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.77, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.80, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.81, Accuracy: 0.00\n",
      "Training: batch 5, Loss: 1.82, Accuracy: 0.00\n",
      "Training: batch 6, Loss: 1.71, Accuracy: 0.14\n",
      "Training: batch 7, Loss: 1.64, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.59, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.62, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.56, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.51, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.51, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.03, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.47, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.23, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.21, Accuracy: 0.71\n",
      "Training: batch 14, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.27, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 18, Loss: 1.28, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.90, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.94, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.96, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.15, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.31, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.29, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.29, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.28, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.30, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.27, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.57, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.66, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.58, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.64, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.57, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.57, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.56, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.58, Accuracy: 0.29\n",
      "Training: batch 14, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.52, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.56, Accuracy: 0.32\n",
      "Training: batch 19, Loss: 1.54, Accuracy: 0.35\n",
      "Training: batch 20, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 21, Loss: 1.55, Accuracy: 0.32\n",
      "Training: batch 22, Loss: 1.53, Accuracy: 0.35\n",
      "Training: batch 23, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 24, Loss: 1.53, Accuracy: 0.36\n",
      "Training: batch 25, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.48, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 34, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.42\n",
      "Training: batch 38, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 39, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 40, Loss: 1.46, Accuracy: 0.39\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 42, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.45, Accuracy: 0.41\n",
      "Training: batch 44, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 48, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 0, Loss: 1.02, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.48, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.28, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.23, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.15, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.95, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.94, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 1.17, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.47, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.54, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 18, Loss: 1.50, Accuracy: 0.37\n",
      "Training: batch 19, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.48, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.48, Accuracy: 0.36\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.35\n",
      "Training: batch 23, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 24, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.46, Accuracy: 0.41\n",
      "Training: batch 34, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.23, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.11, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.08, Accuracy: 0.86\n",
      "Training: batch 7, Loss: 1.18, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.15, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.39, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.50, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.48, Accuracy: 0.17\n",
      "Training: batch 6, Loss: 1.41, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.35, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.39, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.38, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.36, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.37, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.33, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.17, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.11, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.27, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.44, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.46, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.91, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.91, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.21, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.28, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.31, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.12, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.48, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.61, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.67, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.66, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.59, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.62, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 12, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.30, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.29, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.28, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.30, Accuracy: 0.61\n",
      "Training: batch 33, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.95, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.17, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.15, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.22, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.25, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.36, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.31, Accuracy: 0.65\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.32, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.30, Accuracy: 0.65\n",
      "Training: batch 20, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 21, Loss: 1.26, Accuracy: 0.68\n",
      "Training: batch 22, Loss: 1.29, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 24, Loss: 1.31, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.30, Accuracy: 0.65\n",
      "Training: batch 26, Loss: 1.32, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.37, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.40, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.95, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.46, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.55, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.55, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.59, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.55, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.57, Accuracy: 0.31\n",
      "Training: batch 16, Loss: 1.55, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.51, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.51, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 33, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.46, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.44, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.42, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.22, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.30, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.35, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 23, Loss: 1.36, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 28, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.31, Accuracy: 0.63\n",
      "Training: batch 30, Loss: 1.29, Accuracy: 0.65\n",
      "Training: batch 31, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 32, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 33, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 34, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.31, Accuracy: 0.61\n",
      "Training: batch 36, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 37, Loss: 1.30, Accuracy: 0.63\n",
      "Training: batch 38, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.32, Accuracy: 0.62\n",
      "Training: batch 40, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 41, Loss: 1.35, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 43, Loss: 1.34, Accuracy: 0.61\n",
      "Training: batch 44, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 45, Loss: 1.35, Accuracy: 0.61\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.60\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.58\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.57\n",
      "Training: batch 0, Loss: 1.09, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.00, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.27, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.31, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.45, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 22, Loss: 1.28, Accuracy: 0.65\n",
      "Training: batch 23, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 24, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 25, Loss: 1.31, Accuracy: 0.62\n",
      "Training: batch 26, Loss: 1.30, Accuracy: 0.63\n",
      "Training: batch 27, Loss: 1.32, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 35, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.35, Accuracy: 0.58\n",
      "Training: batch 38, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 39, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 41, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 42, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.50, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.27, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.48, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.34, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.58, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.62, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.55, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.58, Accuracy: 0.27\n",
      "Training: batch 11, Loss: 1.56, Accuracy: 0.25\n",
      "Training: batch 12, Loss: 1.51, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.50, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.47, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.44, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.43, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.38, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.33, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.30, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.29, Accuracy: 0.59\n",
      "Training: batch 32, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.30, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.29, Accuracy: 0.59\n",
      "Training: batch 37, Loss: 1.28, Accuracy: 0.61\n",
      "Training: batch 38, Loss: 1.27, Accuracy: 0.62\n",
      "Training: batch 39, Loss: 1.29, Accuracy: 0.60\n",
      "Training: batch 40, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 41, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 42, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 43, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 44, Loss: 1.34, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 3, Loss: 0.97, Accuracy: 1.00\n",
      "Training: batch 4, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 5, Loss: 0.99, Accuracy: 1.00\n",
      "Training: batch 6, Loss: 0.98, Accuracy: 1.00\n",
      "Training: batch 7, Loss: 1.09, Accuracy: 0.88\n",
      "Training: batch 8, Loss: 1.16, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 10, Loss: 1.21, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.27, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.24, Accuracy: 0.69\n",
      "Training: batch 13, Loss: 1.29, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 15, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.31, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.29, Accuracy: 0.63\n",
      "Training: batch 19, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 29, Loss: 1.32, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 42, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.23, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.53, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.47, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.45, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.48, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.46, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.49, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 37, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 40, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 42, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.16, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.11, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.08, Accuracy: 0.83\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.16, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.13, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.21, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.36, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.44, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.83, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.22, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.19, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.14, Accuracy: 0.80\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.30, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.23, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.20, Accuracy: 0.73\n",
      "Training: batch 11, Loss: 1.22, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.27, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.31, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.30, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 25, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.29, Accuracy: 0.61\n",
      "Training: batch 28, Loss: 1.28, Accuracy: 0.62\n",
      "Training: batch 29, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 30, Loss: 1.30, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.21, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.36, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.20, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.40, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.34, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.40, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.49, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.50, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.47, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.48, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 41, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 42, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.90, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.46, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.55, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.60, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.65, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.68, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.60, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.62, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.56, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.60, Accuracy: 0.31\n",
      "Training: batch 13, Loss: 1.56, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 15, Loss: 1.60, Accuracy: 0.31\n",
      "Training: batch 16, Loss: 1.55, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.53, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.52, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.53, Accuracy: 0.38\n",
      "Training: batch 21, Loss: 1.52, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.51, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.43\n",
      "Training: batch 28, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.47, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.85, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.25, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.24, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.33, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.34, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.38, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.40, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 29, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.38, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.99, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.30, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.19, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.16, Accuracy: 0.75\n",
      "Training: batch 8, Loss: 1.13, Accuracy: 0.78\n",
      "Training: batch 9, Loss: 1.21, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.26, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.45, Accuracy: 0.42\n",
      "Training: batch 26, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.43, Accuracy: 0.45\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 39, Loss: 1.43, Accuracy: 0.43\n",
      "Training: batch 40, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 41, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 42, Loss: 1.43, Accuracy: 0.42\n",
      "Training: batch 43, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 44, Loss: 1.43, Accuracy: 0.42\n",
      "Training: batch 45, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 0, Loss: 1.00, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.57, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.62, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.65, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.61, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.58, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.53, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.49, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.52, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.55, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.51, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.47, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.44, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.41, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.34, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 27, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.41, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.90, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.58, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.66, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.53, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.59, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.63, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.64, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.58, Accuracy: 0.30\n",
      "Training: batch 10, Loss: 1.52, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 12, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.54, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 22, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.37, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 1.78, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.22, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.28, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.39, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.39, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.33, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.29, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.38, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.34, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.34, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.33, Accuracy: 0.61\n",
      "Training: batch 18, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.33, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.76, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.83, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.58, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.63, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.53, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.58, Accuracy: 0.29\n",
      "Training: batch 7, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 23, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 24, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 25, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.43, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.02, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.97, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.28, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.19, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.35, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.48, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 11, Loss: 1.47, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.50, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.51, Accuracy: 0.36\n",
      "Training: batch 14, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 16, Loss: 1.48, Accuracy: 0.41\n",
      "Training: batch 17, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.41, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.42, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.41, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.41, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 33, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.92, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.21, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.14, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.29, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.28, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 9, Loss: 1.21, Accuracy: 0.70\n",
      "Training: batch 10, Loss: 1.27, Accuracy: 0.64\n",
      "Training: batch 11, Loss: 1.24, Accuracy: 0.67\n",
      "Training: batch 12, Loss: 1.28, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.30, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.29, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.32, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.34, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.33, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.38, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.40, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.40, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.40, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.94, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.43, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.34, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.27, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.21, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.28, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.28, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.33, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.30, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.27, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.32, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.29, Accuracy: 0.57\n",
      "Training: batch 14, Loss: 1.33, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.31, Accuracy: 0.56\n",
      "Training: batch 16, Loss: 1.29, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.31, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.33, Accuracy: 0.55\n",
      "Training: batch 20, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 21, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.36, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.35, Accuracy: 0.55\n",
      "Training: batch 31, Loss: 1.34, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.32, Accuracy: 0.58\n",
      "Training: batch 33, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 34, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 35, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 36, Loss: 1.33, Accuracy: 0.57\n",
      "Training: batch 37, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.79, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.29, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.20, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.33, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.21, Accuracy: 0.71\n",
      "Training: batch 7, Loss: 1.24, Accuracy: 0.62\n",
      "Training: batch 8, Loss: 1.30, Accuracy: 0.56\n",
      "Training: batch 9, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.32, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.30, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.27, Accuracy: 0.62\n",
      "Training: batch 13, Loss: 1.24, Accuracy: 0.64\n",
      "Training: batch 14, Loss: 1.29, Accuracy: 0.60\n",
      "Training: batch 15, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 16, Loss: 1.32, Accuracy: 0.59\n",
      "Training: batch 17, Loss: 1.35, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 19, Loss: 1.31, Accuracy: 0.60\n",
      "Training: batch 20, Loss: 1.29, Accuracy: 0.62\n",
      "Training: batch 21, Loss: 1.31, Accuracy: 0.59\n",
      "Training: batch 22, Loss: 1.34, Accuracy: 0.57\n",
      "Training: batch 23, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 26, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.39, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.42, Accuracy: 0.47\n",
      "Training: batch 32, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.42, Accuracy: 0.44\n",
      "Training: batch 34, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 35, Loss: 1.41, Accuracy: 0.44\n",
      "Training: batch 36, Loss: 1.40, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.46\n",
      "Training: batch 39, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 1.80, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.81, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.82, Accuracy: 0.00\n",
      "Training: batch 3, Loss: 1.72, Accuracy: 0.00\n",
      "Training: batch 4, Loss: 1.64, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.62, Accuracy: 0.17\n",
      "Training: batch 6, Loss: 1.66, Accuracy: 0.14\n",
      "Training: batch 7, Loss: 1.60, Accuracy: 0.25\n",
      "Training: batch 8, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.49, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.45, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 26, Loss: 1.45, Accuracy: 0.44\n",
      "Training: batch 27, Loss: 1.43, Accuracy: 0.46\n",
      "Training: batch 28, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 29, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 30, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 31, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 35, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.39, Accuracy: 0.51\n",
      "Training: batch 0, Loss: 1.00, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.32, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.21, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.54, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 11, Loss: 1.33, Accuracy: 0.58\n",
      "Training: batch 12, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 13, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 18, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 21, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 22, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 25, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 27, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 31, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 32, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.41, Accuracy: 0.49\n",
      "Training: batch 37, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.42, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 40, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.93, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.45, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 4, Loss: 1.37, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.30, Accuracy: 0.67\n",
      "Training: batch 6, Loss: 1.38, Accuracy: 0.57\n",
      "Training: batch 7, Loss: 1.43, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.48, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.47, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.42, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.46, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.49, Accuracy: 0.38\n",
      "Training: batch 13, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 15, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 16, Loss: 1.53, Accuracy: 0.35\n",
      "Training: batch 17, Loss: 1.52, Accuracy: 0.39\n",
      "Training: batch 18, Loss: 1.54, Accuracy: 0.37\n",
      "Training: batch 19, Loss: 1.51, Accuracy: 0.40\n",
      "Training: batch 20, Loss: 1.50, Accuracy: 0.43\n",
      "Training: batch 21, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 22, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 23, Loss: 1.50, Accuracy: 0.42\n",
      "Training: batch 24, Loss: 1.50, Accuracy: 0.40\n",
      "Training: batch 25, Loss: 1.51, Accuracy: 0.38\n",
      "Training: batch 26, Loss: 1.50, Accuracy: 0.41\n",
      "Training: batch 27, Loss: 1.49, Accuracy: 0.39\n",
      "Training: batch 28, Loss: 1.49, Accuracy: 0.41\n",
      "Training: batch 29, Loss: 1.47, Accuracy: 0.43\n",
      "Training: batch 30, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 31, Loss: 1.47, Accuracy: 0.44\n",
      "Training: batch 32, Loss: 1.46, Accuracy: 0.45\n",
      "Training: batch 33, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 34, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 35, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 36, Loss: 1.45, Accuracy: 0.46\n",
      "Training: batch 37, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 38, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 39, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 40, Loss: 1.43, Accuracy: 0.49\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 46, Loss: 1.38, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.37, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.36, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.87, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.60, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.65, Accuracy: 0.20\n",
      "Training: batch 5, Loss: 1.55, Accuracy: 0.33\n",
      "Training: batch 6, Loss: 1.48, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.52, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.56, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.49, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.45, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.48, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.44, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.43, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.46, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.44, Accuracy: 0.47\n",
      "Training: batch 19, Loss: 1.44, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.42, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 24, Loss: 1.39, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.40, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.40, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 28, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.42, Accuracy: 0.50\n",
      "Training: batch 30, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.39, Accuracy: 0.53\n",
      "Training: batch 34, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.41, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.40, Accuracy: 0.53\n",
      "Training: batch 43, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.56\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.57\n",
      "Training: batch 46, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 47, Loss: 1.39, Accuracy: 0.54\n",
      "Training: batch 48, Loss: 1.38, Accuracy: 0.55\n",
      "Training: batch 0, Loss: 1.90, Accuracy: 0.00\n",
      "Training: batch 1, Loss: 1.79, Accuracy: 0.00\n",
      "Training: batch 2, Loss: 1.49, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.57, Accuracy: 0.25\n",
      "Training: batch 4, Loss: 1.45, Accuracy: 0.40\n",
      "Training: batch 5, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.48, Accuracy: 0.38\n",
      "Training: batch 8, Loss: 1.47, Accuracy: 0.33\n",
      "Training: batch 9, Loss: 1.42, Accuracy: 0.40\n",
      "Training: batch 10, Loss: 1.37, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.39, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.42, Accuracy: 0.43\n",
      "Training: batch 14, Loss: 1.39, Accuracy: 0.47\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 17, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 18, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 19, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 20, Loss: 1.40, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.34, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 25, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 26, Loss: 1.30, Accuracy: 0.59\n",
      "Training: batch 27, Loss: 1.31, Accuracy: 0.57\n",
      "Training: batch 28, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 29, Loss: 1.32, Accuracy: 0.57\n",
      "Training: batch 30, Loss: 1.31, Accuracy: 0.58\n",
      "Training: batch 31, Loss: 1.32, Accuracy: 0.56\n",
      "Training: batch 32, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 33, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 34, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 35, Loss: 1.33, Accuracy: 0.56\n",
      "Training: batch 36, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 37, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 38, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 39, Loss: 1.34, Accuracy: 0.55\n",
      "Training: batch 40, Loss: 1.35, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.49\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 46, Loss: 1.36, Accuracy: 0.51\n",
      "Training: batch 47, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 48, Loss: 1.37, Accuracy: 0.49\n",
      "Training: batch 0, Loss: 0.97, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 0.94, Accuracy: 1.00\n",
      "Training: batch 2, Loss: 1.26, Accuracy: 0.67\n",
      "Training: batch 3, Loss: 1.25, Accuracy: 0.75\n",
      "Training: batch 4, Loss: 1.38, Accuracy: 0.60\n",
      "Training: batch 5, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 6, Loss: 1.40, Accuracy: 0.43\n",
      "Training: batch 7, Loss: 1.34, Accuracy: 0.50\n",
      "Training: batch 8, Loss: 1.40, Accuracy: 0.44\n",
      "Training: batch 9, Loss: 1.35, Accuracy: 0.50\n",
      "Training: batch 10, Loss: 1.38, Accuracy: 0.45\n",
      "Training: batch 11, Loss: 1.42, Accuracy: 0.42\n",
      "Training: batch 12, Loss: 1.39, Accuracy: 0.46\n",
      "Training: batch 13, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 14, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 15, Loss: 1.37, Accuracy: 0.50\n",
      "Training: batch 16, Loss: 1.40, Accuracy: 0.47\n",
      "Training: batch 17, Loss: 1.43, Accuracy: 0.44\n",
      "Training: batch 18, Loss: 1.42, Accuracy: 0.42\n",
      "Training: batch 19, Loss: 1.40, Accuracy: 0.45\n",
      "Training: batch 20, Loss: 1.38, Accuracy: 0.48\n",
      "Training: batch 21, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 22, Loss: 1.34, Accuracy: 0.52\n",
      "Training: batch 23, Loss: 1.33, Accuracy: 0.54\n",
      "Training: batch 24, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 25, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 26, Loss: 1.35, Accuracy: 0.52\n",
      "Training: batch 27, Loss: 1.36, Accuracy: 0.50\n",
      "Training: batch 28, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 29, Loss: 1.35, Accuracy: 0.53\n",
      "Training: batch 30, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 31, Loss: 1.34, Accuracy: 0.53\n",
      "Training: batch 32, Loss: 1.36, Accuracy: 0.52\n",
      "Training: batch 33, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 34, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 35, Loss: 1.38, Accuracy: 0.50\n",
      "Training: batch 36, Loss: 1.37, Accuracy: 0.51\n",
      "Training: batch 37, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 38, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 39, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 40, Loss: 1.36, Accuracy: 0.54\n",
      "Training: batch 41, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 42, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 43, Loss: 1.39, Accuracy: 0.50\n",
      "Training: batch 44, Loss: 1.38, Accuracy: 0.51\n",
      "Training: batch 45, Loss: 1.37, Accuracy: 0.52\n",
      "Training: batch 46, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 47, Loss: 1.38, Accuracy: 0.52\n",
      "Training: batch 48, Loss: 1.37, Accuracy: 0.53\n",
      "Training: batch 0, Loss: 0.91, Accuracy: 1.00\n",
      "Training: batch 1, Loss: 1.41, Accuracy: 0.50\n",
      "Training: batch 2, Loss: 1.52, Accuracy: 0.33\n",
      "Training: batch 3, Loss: 1.59, Accuracy: 0.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-dbe2072f8872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindicator_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindicator_Y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     history = model.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m     45\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         epochs=n_epochs, verbose=0, callbacks=[EndingLossAccCallback()])\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample test run\n",
    "n_epochs = 100\n",
    "\n",
    "    \n",
    "train_index = np.arange(1, 50)\n",
    "test_index = np.arange(1)\n",
    "\n",
    "# input embeddings are the same for each indicator\n",
    "X_train = vec_embeddings[train_index]\n",
    "X_test = vec_embeddings[test_index]\n",
    "\n",
    "# expand input to fit input layer\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "print(np.shape(X_train))\n",
    "\n",
    "# there's probably a better way to do this -_-\n",
    "indicator_models = {}\n",
    "indicator_Y_train = {}\n",
    "indicator_Y_test = {}\n",
    "\n",
    "# generate a neural network model for each indicator\n",
    "for indicator in indicators:\n",
    "    output_layer_length = indicators_df.loc[indicator]['size of unique truth labels']\n",
    "    truth_labels = indicators_df.loc[indicator]['truth label values']\n",
    "    \n",
    "    # output labels are based on indicator\n",
    "    Y_train = truth_labels[train_index]\n",
    "    Y_test = truth_labels[test_index]\n",
    "\n",
    "    # define model for indicator\n",
    "    model = model_def(output_layer_length)\n",
    "    model.summary()\n",
    "    \n",
    "    # store handle to model and data as dict\n",
    "    indicator_models[indicator] = model\n",
    "    indicator_Y_train[indicator] = Y_train\n",
    "    indicator_Y_test[indicator] = Y_test\n",
    "\n",
    "# TRAIN ALLL THE MODELS!!!\n",
    "for indicator in indicators:\n",
    "    model = indicator_models[indicator]\n",
    "    Y_train = indicator_Y_train[indicator]\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=10,\n",
    "                        epochs=n_epochs, verbose=0,\n",
    "                        callbacks=[EndingLossAccCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 809us/step - loss: 0.7453 - accuracy: 1.0000\n",
      "1.0\n",
      "Output Vector: \n",
      "[[9.99995112e-01 4.89134254e-06 9.17543493e-13 1.84507565e-09]\n",
      " [9.99999166e-01 7.81061885e-07 1.11542817e-12 1.37697276e-09]\n",
      " [9.99995351e-01 4.60555702e-06 8.41760635e-13 1.66954417e-09]\n",
      " [9.99998927e-01 1.07666517e-06 4.31751206e-12 3.07028070e-09]\n",
      " [9.99999762e-01 2.72568542e-07 5.14497130e-14 2.18451410e-10]\n",
      " [9.99999642e-01 2.99846789e-07 7.95574815e-14 2.90895280e-10]\n",
      " [9.25966788e-08 7.67067715e-04 9.99228358e-01 4.50005518e-06]\n",
      " [9.25966788e-08 7.67067715e-04 9.99228358e-01 4.50005518e-06]\n",
      " [9.25966788e-08 7.67067715e-04 9.99228358e-01 4.50005518e-06]\n",
      " [9.99995828e-01 4.15138993e-06 3.38267652e-12 3.74361608e-09]\n",
      " [9.99997616e-01 2.44372018e-06 1.15519280e-12 1.82320536e-09]\n",
      " [9.99999762e-01 2.10100822e-07 3.83975925e-14 1.63742103e-10]\n",
      " [9.99999523e-01 4.96138227e-07 1.98381730e-13 5.26731159e-10]\n",
      " [9.99999166e-01 7.90294393e-07 1.74759255e-13 4.97712538e-10]\n",
      " [9.99999881e-01 1.65832020e-07 8.34137176e-14 2.45866993e-10]\n",
      " [9.99999762e-01 1.90728983e-07 1.13647834e-13 3.07563280e-10]\n",
      " [3.43616585e-12 5.42690861e-04 9.99457300e-01 2.21576464e-08]\n",
      " [1.98419892e-11 1.34932820e-03 9.98650610e-01 6.89058837e-08]\n",
      " [7.75707304e-05 9.98530269e-01 1.37331500e-03 1.88249669e-05]\n",
      " [9.99995708e-01 4.26866018e-06 2.39372237e-12 3.06181458e-09]]\n",
      "Output Vector Rounded: \n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Output Label: [0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0]\n",
      "Output Label: [2 0 1 3 1 0 2 0 2 2 3 0 1 2 0 0 2 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# apply testing set\n",
    "test_loss, test_acc = model.evaluate(X_test,  Y_test, verbose=1)\n",
    "print(test_acc)\n",
    "\n",
    "# predict a few samples\n",
    "output = model.predict(X_train[0:20])\n",
    "print(f'Output Vector: \\n{output}')\n",
    "print(f'Output Vector Rounded: \\n{np.round(output)}')\n",
    "print('Output Label: {}'.format([np.where(r==1)[0][0] for r in np.round(output)]))\n",
    "print('Output Label: {}'.format(Y_train[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model_def() missing 1 required positional argument: 'last_layer_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-80d9d85e2995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# reset model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# apply training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: model_def() missing 1 required positional argument: 'last_layer_size'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 50\n",
    "n_epochs = 1500\n",
    "test_accuracy = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "kf.get_n_splits(vec_embeddings)\n",
    "for k_index, (train_index, test_index) in enumerate(kf.split(vec_embeddings)):\n",
    "    X_train = vec_embeddings[train_index]\n",
    "    Y_train = truth_labels[train_index]\n",
    "    \n",
    "    X_test = vec_embeddings[test_index]\n",
    "    Y_test = truth_labels[test_index]\n",
    "    \n",
    "    # expand input\n",
    "    X_train = np.expand_dims(X_train, 2)\n",
    "    X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "    # reset model\n",
    "    model = model_def()\n",
    "    \n",
    "    # apply training set\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=10,\n",
    "                        epochs=n_epochs, show=n_epochs%80==0, verbose=0);\n",
    "                        # We pass some validation for\n",
    "                        # monitoring validation loss and metrics\n",
    "                        # at the end of each epoch\n",
    "                        #validation_data=(x_val, y_val))\n",
    "    \n",
    "    # apply testing set\n",
    "    test_loss, test_acc = model.evaluate(X_test,  Y_test, verbose=1)\n",
    "    \n",
    "    # record accuracy on testing\n",
    "    test_accuracy.append(test_acc)\n",
    "    \n",
    "    print(f'Running Fold Number {k_index}')\n",
    "    print(f'Size of Training Set: {len(train_index)}')\n",
    "    print(f'Size of Testing Set: {len(test_index)}: {test_index}')\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "    print('------------------------')\n",
    "    #model.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'Average accuracy from a {n_folds}-Fold test: {average_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
